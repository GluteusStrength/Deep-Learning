{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b15b9-efc3-48e4-916b-e720d734feeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.models as models\n",
    "import timm\n",
    "import os\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "\n",
    "model = timm.create_model(\"convnext_xlarge.fb_in22k\", pretrained = True, num_classes = 25)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff1aad0-e434-4169-b98b-415f3b7d5135",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random_tensor = torch.rand([64, 3, 224, 224])\n",
    "# x = model(random_tensor)\n",
    "# x.size()\n",
    "# # x = x.view(x.size(0), -1)\n",
    "# # x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426bb55-5325-4e85-96e2-bca601ed283a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"LEARNING_RATE\": 4e-5,\n",
    "    \"EPOCHS\": 20,\n",
    "    \"BATCH_SIZE\": 32,\n",
    "    \"DEVICE\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06636100-09ec-4ac1-b1c7-0ab7808a954d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageSet(Dataset):\n",
    "    def __init__(self, img, transform = None, class_name = None, label = None):\n",
    "        self.img = img\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.class_name = class_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images = self.img[idx]\n",
    "        label = self.label[idx]\n",
    "        img = cv2.imread(images)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image = img)[\"image\"]\n",
    "        label = class_name[label]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec43d4-2771-4cef-959c-8619e9bb99d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentSet(Dataset):\n",
    "    def __init__(self, img, transform = None, class_name = None, label = None):\n",
    "        self.img = img\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.class_name = class_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images = self.img[idx]\n",
    "        label = self.label[idx]\n",
    "        img = cv2.imread(images)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image = self.transform(image = img)[\"image\"]\n",
    "        label = class_name[label]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f923b-2bf1-44b2-80f0-f4a865320bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "transform_augment = A.Compose([\n",
    "    A.Resize(height = 224, width = 224),\n",
    "    A.OneOf([A.HorizontalFlip(), A.VerticalFlip(), A.RandomRotate90()], p = 0.8),\n",
    "    A.OneOf([A.GaussianBlur(blur_limit = (1, 5)), A.MedianBlur(blur_limit = (1, 5))], p = 0.2),\n",
    "    A.OneOf([A.RandomBrightnessContrast(brightness_limit = 0.1, contrast_limit = 0.1),\\\n",
    "             A.CLAHE()], p = 0.5),\n",
    "    # A.OneOf([A.ElasticTransform(), A.GridDistortion()], p = 0.1),\n",
    "    ToTensorV2()\n",
    "])\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "data = pd.read_csv(\"train_.csv\")\n",
    "trainset, valset, _, _ = train_test_split(data, data[\"label\"], test_size = 0.1, stratify = data[\"label\"], random_state = 42)\n",
    "# _, augmentset, _, _ = train_test_split(trainset, trainset[\"label\"], test_size = 0.5, stratify = trainset[\"label\"], random_state = 42)\n",
    "trainset = trainset.reset_index()\n",
    "trainset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "valset = valset.reset_index()\n",
    "valset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "# augmentset = augmentset.reset_index()\n",
    "# augmentset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "augmentset = trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb62e836-e822-48ea-874f-2f84ef2db7df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sampling For Augmentation\n",
    "label = trainset[\"label\"]\n",
    "nums = np.unique(label, return_counts = True)\n",
    "max_num = np.max(nums[1])\n",
    "def balancing(df, nums):\n",
    "    for i in range(len(nums[0])):\n",
    "        label_name = nums[0][i]\n",
    "        n = nums[1][i]\n",
    "        N = max_num - int(n)\n",
    "        if N == 0:\n",
    "            continue\n",
    "        sample = trainset[trainset[\"label\"] == label_name].sample(N)\n",
    "        if df is None:\n",
    "            df = sample\n",
    "        else:\n",
    "            df = pd.concat([df, sample], axis = 0)\n",
    "    return df\n",
    "balance_aug = balancing(None, nums)\n",
    "balance_aug.reset_index(inplace = True)\n",
    "balance_aug.drop([\"index\"], axis = 1, inplace = True)\n",
    "# augmentset = pd.concat([augmentset, balance_aug], axis = 0)\n",
    "# augmentset.reset_index(inplace = True)\n",
    "# augmentset.drop([\"index\"], axis = 1, inplace = True)\n",
    "# augmentset = balance_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff2c59-1324-49ae-a60b-a502bc55df1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = np.unique(data[\"label\"])\n",
    "class_name = {name: i for i, name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b760fe6-9bed-4888-9de8-638d56acbca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = ImageSet(img = trainset[\"upscale_img_path\"], transform = transform, class_name = class_name, label = trainset[\"label\"])\n",
    "validset = ImageSet(img = valset[\"upscale_img_path\"], transform = transform, class_name = class_name, label = valset[\"label\"])\n",
    "augmentset = AugmentSet(img = augmentset[\"upscale_img_path\"], transform = transform_augment, class_name = class_name, label = augmentset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1713a84-6aa0-408d-940a-bb591743ecfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trainset), len(augmentset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef54b49-4624-4502-a639-b570cb840dac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualization(flag: bool = False):\n",
    "    if flag:\n",
    "        image1, image2 = augmentset[103][0], augmentset[2000][0]\n",
    "        print(image1.size())\n",
    "        image1_np = image1.numpy().transpose((1, 2, 0))\n",
    "        image2_np = image2.numpy().transpose((1, 2, 0))\n",
    "        image1_np = (image1_np - image1_np.min()) / (image1_np.max() - image1_np.min())\n",
    "        image2_np = (image2_np - image2_np.min()) / (image2_np.max() - image2_np.min())\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image1_np)\n",
    "        plt.title('Image 1')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2_np)\n",
    "        plt.title('Image 2')\n",
    "\n",
    "        plt.show()\n",
    "visualization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43935df6-e48d-41fb-af1d-777ae07d0cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainset = trainset + augmentset\n",
    "trainloader = DataLoader(trainset + augmentset, batch_size = CFG[\"BATCH_SIZE\"], shuffle = True, num_workers = 0)\n",
    "validloader = DataLoader(validset, batch_size = CFG[\"BATCH_SIZE\"], shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f36489-99df-4067-aefe-ed599a26bf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,\\\n",
    "    threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    val_score = []\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for imgs, labels in tqdm(iter(train_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 Score : [{_val_score:.5f}]')\n",
    "        val_score.append(np.round(_val_score, 5))\n",
    "       \n",
    "        if scheduler is not None:\n",
    "            # validation score를 기준으로 scheduler를 조정한다\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = model\n",
    "            torch.save(best_model, \"best_xlarge_model_v2.pt\")\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}], Best Val F1 Score : [{_val_score:.5f}]')\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(val_score)\n",
    "        for i, value in enumerate(val_score):\n",
    "            plt.text(i, value, str(value), fontsize=12, ha='center')\n",
    "        plt.savefig('xlarge_backbone.png', dpi=300, format='png')\n",
    "\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b5b3a-d05d-4d26-9723-b35bd89356ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(iter(val_loader)):\n",
    "            imgs = imgs.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            pred = model(imgs)\n",
    "            \n",
    "            loss = criterion(pred, labels)\n",
    "            \n",
    "            preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14413ae-598f-4da7-bd45-25120750204d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_model = train(model, optimizer, trainloader, validloader,\\\n",
    "    scheduler, device = CFG[\"DEVICE\"])\n",
    "# torch.save(infer_model, \"best_model_CONVNEXT_30epochs_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af14f24c-4ad4-44be-82ec-929e9ebda089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # model = torch.load(\"best_model_CONVNEXT_30epochs_super.pt\")\n",
    "# # model.to(CFG[\"DEVICE\"])\n",
    "# class TestSet(Dataset):\n",
    "#     def __init__(self, img, transform = None):\n",
    "#         self.img = img\n",
    "#         self.transform = transform\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.img)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         image = self.img[idx]\n",
    "#         image = cv2.imread(image)\n",
    "#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "#         return image\n",
    "# transform_ = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "#     transforms.Resize([224, 224], interpolation = InterpolationMode.BICUBIC)                    \n",
    "# ])\n",
    "# test = pd.read_csv(\"test_.csv\")\n",
    "# test_set = TestSet(img = test[\"img_path\"], transform = transform_)\n",
    "# test_loader = DataLoader(test_set, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdb3b31-8c9d-42e2-bb5b-268be9acd88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def inference(model, test_loader, device):\n",
    "#     model.to(device)\n",
    "#     model.eval()\n",
    "#     preds = []\n",
    "#     with torch.no_grad():\n",
    "#         for imgs in tqdm(iter(test_loader)):\n",
    "#             imgs = imgs.float().to(CFG[\"DEVICE\"])\n",
    "#             pred = model(imgs)\n",
    "#             preds += pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "    \n",
    "#     return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98298045-9d94-4870-8a0f-4ce5d39423e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# preds = inference(model, test_loader, device = CFG[\"DEVICE\"])\n",
    "# classes = list(class_name.keys())\n",
    "# final = []\n",
    "# for pred in preds:\n",
    "#     final.append(classes[pred])\n",
    "# submit = pd.read_csv(\"./sample_submission.csv\")\n",
    "# submit[\"label\"] = final\n",
    "# submit.to_csv(\"./submit_30epochs_xlarge_.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
