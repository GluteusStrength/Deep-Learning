{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc1dc3-4771-4d04-baa1-a940d9910dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f050823b-df03-40de-91b9-9f09c45d3c1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "classes = np.unique(data[\"label\"])\n",
    "class_name = {name: i for i, name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4449abd-6d98-4794-b5ad-b25bbfbbeaed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Augmentset(Dataset):\n",
    "    def __init__(self, img, transform = None, transform_ = None):\n",
    "        self.img = img\n",
    "        self.transform = transform\n",
    "        self.transform_ = transform_\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.img.loc[idx, :]\n",
    "        image1_pth = image[0]\n",
    "        image2_pth = image[0]\n",
    "        image1 = cv2.imread(image1_pth)\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)\n",
    "        image2 = cv2.imread(image2_pth)\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image1 = self.transform(image1)\n",
    "        if self.transform_:\n",
    "            image2 = self.transform_(image2)\n",
    "        return image1, image2\n",
    "\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    # transforms.RandomApply(\n",
    "    #     [# brightness, contrast, saturation, hue\n",
    "    #     transforms.ColorJitter(0.5, 0.5, 0.5, 0.2)\n",
    "    #     ], p = 0.5\n",
    "    # ),\n",
    "    transforms.RandomApply(\n",
    "        [# brightness, contrast, saturation, hue\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.GaussianBlur(kernel_size = 3, sigma = (1.0, 2.0))\n",
    "        ], p = 1\n",
    "    ),\n",
    "    ]                    \n",
    ")\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    transforms.Resize(224),\n",
    "    transforms.GaussianBlur(kernel_size = 3, sigma = (1.0, 2.0))\n",
    "]                   \n",
    ")\n",
    "\n",
    "images = data\n",
    "data = Augmentset(img = images, transform = transform, transform_ = transform_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faee25a-bcc7-4676-abce-7338f49ebd9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualization(flag: bool = False):\n",
    "    if flag:\n",
    "        image1, image2 = data[24]\n",
    "        print(image1.size())\n",
    "        image1_np = image1.numpy().transpose((1, 2, 0))\n",
    "        image2_np = image2.numpy().transpose((1, 2, 0))\n",
    "        image1_np = (image1_np - image1_np.min()) / (image1_np.max() - image1_np.min())\n",
    "        image2_np = (image2_np - image2_np.min()) / (image2_np.max() - image2_np.min())\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image1_np)\n",
    "        plt.title('Image 1')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2_np)\n",
    "        plt.title('Image 2')\n",
    "\n",
    "        plt.show()\n",
    "visualization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f733c-aaed-4dc5-a979-6b7ac2ea71bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def nt_xent(x1, x2, t):\n",
    "    # calcularte cosinesimilarity\n",
    "    # x1[None, :, :] -> change the dimension of matrix\n",
    "    # cos_sim -> 32 x 32 matrix -> batch 단위로 cosine similarity 계산\n",
    "    N = x1.size(0)\n",
    "    similarity = F.cosine_similarity(x1[None, :, :], x2[:, None, :], dim = -1)\n",
    "    # to remove the calcuation of itself.\n",
    "    mask = torch.eye(N, dtype = torch.bool).to(device)\n",
    "    similarity /= t\n",
    "    neg_sample = similarity.clone()\n",
    "    neg_sample[mask.bool()] = float(\"-inf\")\n",
    "    similarity, neg_sample = torch.exp(similarity), torch.exp(neg_sample)\n",
    "    probs = similarity / torch.sum(neg_sample, dim = 1)\n",
    "    loss = -torch.log(probs.diagonal())\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b98a7d8-5c9e-40d0-ac82-c736d4af1662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(data, batch_size = 32, shuffle = True)\n",
    "# for i, j in trainloader:\n",
    "#     print(i.size())\n",
    "#     print(j.size())\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c92f5a-aa90-47d4-b539-53946468cf72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnext = timm.create_model(\"convnext_base.fb_in22k\", pretrained = True, num_classes = 0)\n",
    "# random tensor\n",
    "convnext = torch.nn.Sequential(*list(convnext.children())[:-1])\n",
    "# srcnn = torch.load(\"best_psnr.pt\")\n",
    "# random_tensor = torch.ones([256, 3, 224, 224])\n",
    "# effnet(random_tensor).size()\n",
    "# convnext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53342ae3-6aaa-4e08-80e0-55687b655414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random_tensor = torch.ones([256, 3, 224, 224])\n",
    "# convnext(random_tensor).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e69caf-0cb0-477e-b27d-810c442aeec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class simCLR(nn.Module):\n",
    "    def __init__(self, embedding_size, model):\n",
    "        super(simCLR, self).__init__()\n",
    "        self.backbone = model\n",
    "        self.fc1 = nn.Linear(1024 * 7 * 7, 2048)\n",
    "        self.fc2 = nn.Linear(2048, embedding_size)\n",
    "        torch.nn.init.kaiming_normal_(self.fc1.weight)\n",
    "        torch.nn.init.kaiming_normal_(self.fc2.weight)\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = x.reshape(-1, 1024 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0738e033-aa0f-405f-bfb3-8cd281a8c943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = simCLR(embedding_size = 128, model = convnext)\n",
    "# model = torch.load(\"resolution_ssl_11_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab057b-0219-4ab4-b177-60b4800ecd3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fe8728-b14d-4bee-9aa2-139a533f9461",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "optimizer = optim.AdamW(params = model.parameters(), lr = 1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa081a-7fba-4ace-96b0-1a88033c6faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "best_loss = 9999999\n",
    "for epoch in range(1, 10 + 1):\n",
    "    # 모델을 훈련 모드로 설정하는 method\n",
    "    model.train()\n",
    "    train_loss = []\n",
    "    temperature = 0.5\n",
    "    for img1, img2 in tqdm(trainloader):\n",
    "        img1 = img1.to(device)\n",
    "        img2 = img2.to(device)\n",
    "        output1 = model(img1)\n",
    "        output2 = model(img2)\n",
    "        optimizer.zero_grad()\n",
    "        loss = nt_xent(output1, output2, temperature)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    _train_loss = np.mean(train_loss)\n",
    "    scheduler.step()\n",
    "    if best_loss > _train_loss:\n",
    "        best_loss = _train_loss\n",
    "        best_model = model\n",
    "        torch.save(best_model, \"res_ssl_{}_.pt\".format(epoch))\n",
    "        print(\"Best Loss: {}\".format(best_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa466bd-fbf8-4c91-ad81-cbe6f597823f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
