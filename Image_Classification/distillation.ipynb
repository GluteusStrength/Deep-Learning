{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b15b9-efc3-48e4-916b-e720d734feeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "# import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import torchvision.models as models\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import timm\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything()\n",
    "\n",
    "# Self-Distillation 효과를 보고자 한다.\n",
    "# 자체적으로 처리하기 보다는 2-Stage를 통해서 진행해본다.\n",
    "# Teacher의 경우는 모두 Freeze를 시킨다.\n",
    "# Student의 경우는 최대한 Low-Resolution image를 통해 최적화를 시킨다.\n",
    "teacher = torch.load(\"best_xlarge_model.pt\", map_location = \"cpu\")\n",
    "student = torch.load(\"best_xlarge_model.pt\", map_location = \"cpu\")\n",
    "# student = timm.create_model(\"convnext_large.fb_in22k\", pretrained = True, num_classes = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1adb20-c70f-4d17-97f8-9ecd0693bce5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "extraction_teacher = torch.nn.Sequential(*list(teacher.children())[:-1])\n",
    "extraction_student = torch.nn.Sequential(*list(student.children())[:-1])\n",
    "head_teacher = teacher.head\n",
    "head_student = student.head\n",
    "\n",
    "class ConvNext(nn.Module):\n",
    "    def __init__(self, extraction, head):\n",
    "        super(ConvNext, self).__init__()\n",
    "        self.extraction = extraction\n",
    "        self.head = head\n",
    "    def forward(self, x):\n",
    "        x1 = self.extraction(x)\n",
    "        x2 = self.head(x1)\n",
    "        return x1, x2\n",
    "\n",
    "def freeze(model):\n",
    "    for i, (name, param) in enumerate(model.named_parameters()):\n",
    "        param.requires_grad = False\n",
    "freeze(extraction_teacher)\n",
    "freeze(head_teacher)\n",
    "teacher = ConvNext(extraction = extraction_teacher, head = head_teacher)\n",
    "student = ConvNext(extraction = extraction_student, head = head_student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2af405-1abf-4d7e-9664-c169f4d39e6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_tensor = torch.rand([64, 3, 224, 224])\n",
    "x = student(random_tensor)\n",
    "x[0].size(), x[1].size()\n",
    "# x = x.view(x.size(0), -1)\n",
    "# x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e90c5f-aa77-448d-bb12-9c2bd703a2d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name, param in student.named_parameters():\n",
    "    print(f\"{name}: requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426bb55-5325-4e85-96e2-bca601ed283a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# best learning rate: 5e-5\n",
    "CFG = {\n",
    "    \"LEARNING_RATE\": 5e-5,\n",
    "    \"EPOCHS\": 30,\n",
    "    \"BATCH_SIZE\": 16,\n",
    "    \"DEVICE\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06636100-09ec-4ac1-b1c7-0ab7808a954d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ImageSet(Dataset):\n",
    "    def __init__(self, img_low, img_high, transform = None, class_name = None, label = None):\n",
    "        self.img_low = img_low\n",
    "        self.img_high = img_high\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.class_name = class_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images_low = self.img_low[idx]\n",
    "        images_high = self.img_high[idx]\n",
    "        label = self.label[idx]\n",
    "        imgs_low = cv2.imread(images_low)\n",
    "        imgs_low = cv2.cvtColor(imgs_low, cv2.COLOR_BGR2RGB)\n",
    "        imgs_high = cv2.imread(images_high)\n",
    "        imgs_high = cv2.cvtColor(imgs_high, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform:\n",
    "            image_low = self.transform(image = imgs_low)[\"image\"]\n",
    "            image_high = self.transform(image = imgs_high)[\"image\"]\n",
    "        label = class_name[label]\n",
    "        return image_low, image_high, label\n",
    "    \n",
    "\n",
    "class AugmentSet(Dataset):\n",
    "    def __init__(self, img_low, img_high, transform = None, transform_augment = None, class_name = None, label = None):\n",
    "        self.img_low = img_low\n",
    "        self.img_high = img_high\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "        self.class_name = class_name\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        images_low = self.img_low[idx]\n",
    "        images_high = self.img_high[idx]\n",
    "        label = self.label[idx]\n",
    "        imgs_low = cv2.imread(images_low)\n",
    "        imgs_low = cv2.cvtColor(imgs_low, cv2.COLOR_BGR2RGB)\n",
    "        imgs_high = cv2.imread(images_high)\n",
    "        imgs_high = cv2.cvtColor(imgs_high, cv2.COLOR_BGR2RGB)\n",
    "        if self.transform_augment:\n",
    "            image_low = self.transform_augment(image = imgs_low)[\"image\"]\n",
    "        if self.transform:    \n",
    "            image_high = self.transform(image = imgs_high)[\"image\"]\n",
    "        label = class_name[label]\n",
    "        return image_low, image_high, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9f923b-2bf1-44b2-80f0-f4a865320bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(height=224, width=224),\n",
    "    A.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "transform_augment = A.Compose([\n",
    "    A.Resize(height = 224, width = 224),\n",
    "    A.OneOf([A.HorizontalFlip(), A.VerticalFlip(), A.RandomRotate90()], p = 1),\n",
    "    # A.OneOf([A.GaussianBlur(blur_limit = (1, 5)), A.MedianBlur(blur_limit = (1, 5))], p = 0.2),\n",
    "    A.OneOf([A.RandomBrightnessContrast(brightness_limit = 0.1, contrast_limit = 0.1),\\\n",
    "             A.CLAHE()], p = 0.5),\n",
    "    # A.OneOf([A.ElasticTransform(), A.GridDistortion()], p = 0.1),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"train_.csv\")\n",
    "trainset, valset, _, _ = train_test_split(data, data[\"label\"], test_size = 0.1, stratify = data[\"label\"], random_state = 42)\n",
    "_, augmentset, _, _ = train_test_split(trainset, trainset[\"label\"], test_size = 0.5, stratify = trainset[\"label\"], random_state = 42)\n",
    "trainset = trainset.reset_index()\n",
    "trainset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "valset = valset.reset_index()\n",
    "valset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "augmentset = augmentset.reset_index()\n",
    "augmentset.drop([\"index\", \"Unnamed: 0\"], axis = 1, inplace = True)\n",
    "# augmentset = trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c7d6a-41d6-4e9c-92df-b22d1e33dba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.unique(trainset[\"label\"], return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ff2c59-1324-49ae-a60b-a502bc55df1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = np.unique(data[\"label\"])\n",
    "class_name = {name: i for i, name in enumerate(classes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b760fe6-9bed-4888-9de8-638d56acbca4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainset = ImageSet(img_low = trainset[\"img_path\"], img_high = trainset[\"upscale_img_path\"], transform = transform, class_name = class_name, label = trainset[\"label\"])\n",
    "validset = ImageSet(img_low = valset[\"img_path\"], img_high = valset[\"upscale_img_path\"], transform = transform, class_name = class_name, label = valset[\"label\"])\n",
    "augmentset = ImageSet(img_low = augmentset[\"img_path\"], img_high = augmentset[\"upscale_img_path\"], transform = transform_augment, class_name = class_name, label = augmentset[\"label\"])\n",
    "# augmentset2 = ImageSet(img_low = augmentset[\"img_path\"], img_high = augmentset[\"upscale_img_path\"], transform = transform_augment, class_name = class_name, label = augmentset[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0917ee4f-41a2-45e7-ba17-0d8fb0b4a841",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def visualization(flag: bool = False):\n",
    "    if flag:\n",
    "        image1, image2 = trainset[0][0], augmentset[0][0]\n",
    "        print(image1.size())\n",
    "        image1_np = image1.numpy().transpose((1, 2, 0))\n",
    "        image2_np = image2.numpy().transpose((1, 2, 0))\n",
    "        image1_np = (image1_np - image1_np.min()) / (image1_np.max() - image1_np.min())\n",
    "        image2_np = (image2_np - image2_np.min()) / (image2_np.max() - image2_np.min())\n",
    "        plt.figure(figsize=(10, 5))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image1_np)\n",
    "        plt.title('Image 1')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(image2_np)\n",
    "        plt.title('Image 2')\n",
    "\n",
    "        plt.show()\n",
    "visualization(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43935df6-e48d-41fb-af1d-777ae07d0cb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset + augmentset, batch_size = CFG[\"BATCH_SIZE\"], shuffle = True, num_workers = 0)\n",
    "validloader = DataLoader(validset, batch_size = CFG[\"BATCH_SIZE\"], shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d28d50-15a6-4768-b9b7-e0f95ceb5be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(trainset), len(validset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c9112-53f3-49c3-9f13-44fa5060abef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, (name, param) in enumerate(teacher.named_parameters()):\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bcb63e-1eaf-4515-a8ab-08ab53079fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 public 기준 좋은 alpha: 0.2, T: 3이 베스트 score\n",
    "# alpha가 낮을 수록 학생 모델 학습에 집중\n",
    "# temperature가 높을 수록 Hard Task를 학습하는 데 집중\n",
    "# 초반부에는 Temperature가 낮기 때문에 alpha값을 낮은 값부터 시작해서 쉬운 것에 대해서는 우선 모델 자체적으로 학습 가능하게\n",
    "# 후반부에는 Temperature가 높기 때문에 alpha값을 상대적으로 높게해서 모델의 output을 따르도록 해본다/\n",
    "def distillation_loss(logits, labels, teacher_logits, student_rprs, teacher_rprs, mse_loss, temperature):\n",
    "    # base alpha = temperature / 10\n",
    "    alpha = 0.1\n",
    "    T = temperature\n",
    "    student_loss = F.cross_entropy(input = logits, target = labels)\n",
    "    KL_div = nn.KLDivLoss(reduction = \"batchmean\")(F.log_softmax(logits/T, dim = 1), F.softmax(teacher_logits/T, dim = 1)) * (T*T)\n",
    "    mse = mse_loss(teacher_rprs, student_rprs)\n",
    "    total_loss = (1-alpha)*student_loss + alpha*KL_div + mse\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f36489-99df-4067-aefe-ed599a26bf8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(params = student.parameters(), lr = CFG[\"LEARNING_RATE\"], weight_decay = 1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\\\n",
    "    threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
    "\n",
    "def train(teacher, student, optimizer, train_loader, val_loader, scheduler, device):\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()\n",
    "    # criterion = nn.CrossEntropyLoss().to(device)\n",
    "    temperature = 3\n",
    "    best_score = 0\n",
    "    best_model = None\n",
    "    val_score = []\n",
    "    iteration_cnt = 0\n",
    "    mse_loss = nn.MSELoss()\n",
    "    for epoch in range(1, CFG['EPOCHS']+1):\n",
    "        student.train()\n",
    "        train_loss = []\n",
    "        iteration_cnt += 1\n",
    "        for i_low, i_high, labels in tqdm(iter(train_loader)):\n",
    "            i_low = i_low.float().to(device)\n",
    "            i_high = i_high.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            student_rprs, student_output = student(i_low)\n",
    "            teacher_rprs, teacher_output = teacher(i_high)\n",
    "            loss = distillation_loss(student_output, labels, teacher_output, student_rprs, teacher_rprs, mse_loss, temperature)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss, _val_score = validation(teacher, student, val_loader, device, temperature)\n",
    "        \n",
    "        if iteration_cnt == 10:\n",
    "            if temperature <= 5:\n",
    "                iteration_cnt = 0\n",
    "                print(\"Temperature upscaled: {}\".format(temperature))\n",
    "                    \n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 Score : [{_val_score:.5f}]')\n",
    "        \n",
    "        val_score.append(np.round(_val_score, 5))\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            # validation score를 기준으로 scheduler를 조정한다\n",
    "            scheduler.step(_val_score)\n",
    "            \n",
    "        if best_score < _val_score:\n",
    "            best_score = _val_score\n",
    "            best_model = student\n",
    "            torch.save(best_model, \"xlarge_distill_best.pt\")\n",
    "            print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}], Best Val F1 Score : [{_val_score:.5f}]')\n",
    "        \n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plt.plot(val_score)\n",
    "        for i, value in enumerate(val_score):\n",
    "            plt.text(i, value, str(value), fontsize=12, ha='center')\n",
    "        plt.savefig('xlarge_best.png', dpi=300, format='png')\n",
    "\n",
    "    \n",
    "    return best_model, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618b5b3a-d05d-4d26-9723-b35bd89356ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation(teacher, student, val_loader, device, temperature):\n",
    "    student.eval()\n",
    "    val_loss = []\n",
    "    preds, true_labels = [], []\n",
    "    mse_loss = nn.MSELoss()\n",
    "    with torch.no_grad():\n",
    "        for i_low, i_high, labels in tqdm(iter(val_loader)):\n",
    "            i_low = i_low.float().to(device)\n",
    "            i_high = i_high.float().to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            student_rprs, student_pred = student(i_low)\n",
    "            teacher_rprs, teacher_pred = teacher(i_high)\n",
    "            loss = distillation_loss(student_pred, labels, teacher_pred, student_rprs, teacher_rprs, mse_loss, temperature)\n",
    "            \n",
    "            \n",
    "            preds += student_pred.argmax(1).detach().cpu().numpy().tolist()\n",
    "            true_labels += labels.detach().cpu().numpy().tolist()\n",
    "            \n",
    "            val_loss.append(loss.item())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "        _val_score = f1_score(true_labels, preds, average='macro')\n",
    "    \n",
    "    return _val_loss, _val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14413ae-598f-4da7-bd45-25120750204d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infer_model = train(teacher, student, optimizer, trainloader, validloader,\\\n",
    "    scheduler = scheduler, device = CFG[\"DEVICE\"])\n",
    "best_model = infer_model[0]\n",
    "scores = infer_model[1]\n",
    "# torch.save(best_model, \"best_model_distillation_fix.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
