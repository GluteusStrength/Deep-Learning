{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"aQbqZ80gBmV4"},"outputs":[],"source":["import os # os module upload\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","from PIL import Image\n","import cv2"]},{"cell_type":"markdown","metadata":{"id":"p52JDOyw0C0n"},"source":["0차 *필터링*\n","\n","*   CYMK, RGBA를 따로 분리\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ckfPiBZ_z_96"},"outputs":[],"source":["def three_channel_filtering(image):\n","    if len(image.shape) == 3:\n","        if image.shape[2] == 3:\n","            return True\n","        else:\n","            return False\n","    else:\n","        return False"]},{"cell_type":"markdown","metadata":{"id":"Mcf2Gjie2D4L"},"source":["first filtering by the comparison of pixels"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NNbLDxOW1i3k"},"outputs":[],"source":["def filtering(image):\n","    count = 0\n","    image_x = image.shape[1] - 1\n","    image_y = image.shape[0] - 1\n","\n","    pixel_list = [image[(0,0)], image[(image_y, 0)], image[(0, image_x)], image[(image_y, image_x)]]\n","\n","    com_list = list(combinations(pixel_list, 2))\n","\n","    for com in com_list:\n","        if all(com[0] == com[1]):\n","            count += 1\n","    \n","    if count >= 3:\n","        return True\n","    else:\n","        return False"]},{"cell_type":"markdown","metadata":{"id":"f9bS5XOC1dZI"},"source":["1st filtering process"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZJ3gzIjO0mWh"},"outputs":[],"source":["org_path = ('/content/drive/MyDrive/Data/org')\n","pre_path = ('/content/drive/MyDrive/Data/preprocessing_1')\n","final_pre_path = ('/content/drive/MyDrive/Data/preprocessing_final')\n","filtered_path = ('/content/drive/MyDrive/Data/1st_filtering')\n","\n","dir_paths = os.listdir(org_path)\n","\n","count = 0\n","\n","for dir_path in dir_paths:\n","    org_paths = os.path.join(org_path, dir_path)\n","    pre_paths = os.path.join(pre_path, dir_path)\n","    final_pre_paths = os.path.join(final_pre_path, dir_path)\n","    filtered_paths = os.path.join(filtered_path, dir_path)\n","    \n","    # os.mkdir(pre_paths)\n","    # os.mkdir(final_pre_paths)\n","    # os.mkdir(filtered_paths)\n","\n","    image_paths = os.listdir(org_paths)\n","\n","    for image_path in image_paths:\n","        count += 1\n","        org_image_path = os.path.join(org_paths, image_path)\n","        pre_image_path = os.path.join(pre_paths, image_path)\n","        final_pre_image_path = os.path.join(final_pre_paths, image_path)\n","        filtered_image_path = os.path.join(filtered_paths, image_path)\n","\n","        image = load_image(org_image_path)\n","        print(org_image_path, count)\n","        if not three_channel_filtering(image):\n","            shutil.move(org_image_path, final_pre_image_path)\n","        elif filtering(image):\n","            shutil.move(org_image_path, pre_image_path)\n","        else:\n","            shutil.move(org_image_path, filtered_image_path)"]},{"cell_type":"markdown","metadata":{"id":"lxMZsamD2OeD"},"source":["2nd filtering (cropped data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W83s4Tk1BzRb"},"outputs":[],"source":["def cropping(image, image_gray):\n","    threshold1 = 30\n","    threshold2 = 60\n","\n","    image_canny = cv2.Canny(image_gray, threshold1, threshold2)\n","\n","    contour_list = np.argwhere(image_canny>0)\n","    y1,x1 = contour_list.min(axis=0)\n","    y2,x2 = contour_list.max(axis=0)\n","\n","    return image[y1:y2, x1:x2]"]},{"cell_type":"markdown","metadata":{"id":"x3vt2Ft506t9"},"source":["이미지의 네 모서리 픽셀값이 같은지를 비교하여 실사 filtering"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C4EvAoII02FG"},"outputs":[],"source":["def filtering2(image):\n","    image_x = image.shape[1] - 1\n","    image_y = image.shape[0] - 1\n","\n","    pixel_list = [image[(0,0)], image[(image_y, 0)], image[(0, image_x)], image[(image_y, image_x)]]\n","\n","    com_list = list(combinations(pixel_list, 2))\n","\n","    for com in com_list:\n","        if all(com[0] == com[1]):\n","            return True\n","    \n","    return False"]},{"cell_type":"markdown","metadata":{"id":"s--Jb3Ue1Eoq"},"source":["2nd filtering process "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HEOMRp31Bz-"},"outputs":[],"source":["org_path = ('/content/drive/MyDrive/Data/preprocessing_1')\n","pre_path = ('/content/drive/MyDrive/Data/preprocessing_2')\n","filtered_path = ('/content/drive/MyDrive/Data/2nd_filtering')\n","\n","dir_paths = os.listdir(org_path)\n","\n","count = 0\n","\n","for dir_path in dir_paths:\n","    org_paths = os.path.join(org_path, dir_path)\n","    pre_paths = os.path.join(pre_path, dir_path)\n","    filtered_paths = os.path.join(filtered_path, dir_path)\n","    \n","    # os.mkdir(pre_paths)\n","    # os.mkdir(filtered_paths)\n","\n","    image_paths = os.listdir(org_paths)\n","\n","    for image_path in image_paths:\n","        count += 1\n","        org_image_path = os.path.join(org_paths, image_path)\n","        pre_image_path = os.path.join(pre_paths, image_path)\n","        filtered_image_path = os.path.join(filtered_paths, image_path)\n","\n","        image = load_image(org_image_path)\n","        image_gray = load_gray_image(org_image_path)\n","        print(org_image_path, count)\n","\n","        crop_image = cropping(image, image_gray)\n","\n","        if filtering2(crop_image):\n","            shutil.move(org_image_path, pre_image_path)\n","        else:\n","            shutil.move(org_image_path, filtered_image_path)"]},{"cell_type":"markdown","metadata":{"id":"RtKhxhTk2MHR"},"source":["**after 2 steps filtering** Datasets upload"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mz5h0piSG1Cp"},"outputs":[],"source":["image_path = '/content/drive/MyDrive/Data/preprocessing_2/'\n","\n","label_path = os.listdir(image_path) # listdir에 파일의 경로가 들어있다\n","\n","label_paths = [os.path.join(image_path,label_path[i]) for i in range(len(label_path))] # L2_#까지 포함된 경로\n","\n","image_jpg = [os.listdir(label_paths[i]) for i in range(len(label_paths))] # JPG명\n","\n","image_paths = [] # 여기에 최종 경로가 저장됨\n","for i in range(len(label_paths)):\n","    sub_paths = []\n","    for j in range(len(image_jpg[i])):\n","        sub_paths.append(os.path.join(label_paths[i], image_jpg[i][j]))\n","    image_paths.append(sub_paths)"]},{"cell_type":"markdown","metadata":{"id":"V57AqbAnnFwW"},"source":["처음으로 실사로 거른 셋에 대한 경로 업로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lDzUQTsLi34j"},"outputs":[],"source":["image_path_1 = '/content/drive/MyDrive/Data/1st_filtering/'\n","\n","label_path_1 = os.listdir(image_path_1) # listdir에 파일의 경로가 들어있다\n","\n","label_paths_1 = [os.path.join(image_path_1,label_path_1[i]) for i in range(len(label_path_1))]\n","\n","image_jpg_1 = [os.listdir(label_paths_1[i]) for i in range(len(label_paths_1))]\n","\n","image_paths_1 = []\n","for i in range(len(label_paths_1)):\n","    sub_paths = []\n","    for j in range(len(image_jpg_1[i])):\n","        sub_paths.append(os.path.join(label_paths_1[i], image_jpg_1[i][j]))\n","    image_paths_1.append(sub_paths)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mP_OVo0LjPqi"},"source":["특정 label에 특히 1차로 거른 실사들이 많다.\n","\n","*   우선 이 클래스들의 사진들의 픽셀값을 0 ~ 50, 50 ~ 200까지는 10단위로, 200 ~ 255까지로 분리한 것을 dataframe으로 만들어줌\n","*   맨 뒤에 해당 사진의 픽셀 분포도의 standard deviation을 구하여 dataframe의 열로 추가\n","*   해당 dataframe이 ISOLATION FOREST의 이상치 탐지의 학습 데이터가 될 것이다. \n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cYqbiDNjicR"},"outputs":[],"source":["dist_real = []\n","img_idx = []\n","pic_class = [\"L2_3\", \"L2_12\", \"L2_24\", \"L2_41\", \"L2_50\"]\n","for i in range(len(label_path)):\n","    if label_path[i] in pic_class:\n","        img_idx.append(i)\n","for i in img_idx:\n","    dist_sub = []\n","    print(i)\n","    for img in image_paths_1[i]:\n","        img = Image.open(img)\n","        img = np.array(img)\n","        check = img.flatten()\n","        dis = []\n","        cnt = 0\n","        for j in range(50, 210, 10):\n","            if j == 50:\n","                dis.append(len(check[check <= j]))\n","                cnt += 1\n","            else:\n","                dis.append(len(check[check <= j]) - sum(dis[:cnt]))\n","                cnt += 1\n","                if j == 200:\n","                    dis.append(len(check[check <= 255]) - sum(dis[:cnt+1]))\n","        dist_sub.append(dis)\n","    dist_real.append(dist_sub)\n","\n","# IsoForest에 돌릴 실사 데이터 모음. 약 1900개\n","dist_df = pd.concat([pd.DataFrame(dist_real[0]),pd.DataFrame(dist_real[1]),pd.DataFrame(dist_real[2]),pd.DataFrame(dist_real[3]),pd.DataFrame(dist_real[4])], ignore_index = True)\n","d_real = dist_df.copy()\n","std_set = []\n","for i in range(len(d_real)):\n","    std_set.append(np.std(d_real.iloc[i]))\n","d_real[\"std\"] = std_set"]},{"cell_type":"markdown","metadata":{"id":"mWvk7pbJ3Rgo"},"source":["2차까지 일러스트라고 분류된 사진 역시 픽셀 범위 별로 DataFrame을 만든다\n","이는 IsolationForest의 테스트 데이터가 된다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b3jNH5wjnW3c"},"outputs":[],"source":["dist_picture = []\n","for i in range(len(image_paths)):\n","    sub_picture = []\n","    print(i)\n","    for img in image_paths[i]:\n","        img = Image.open(img)\n","        img = np.array(img)\n","        check = img.flatten()\n","        dis = []\n","        cnt = 0\n","        for j in range(50, 210, 10):\n","            if j == 50:\n","                dis.append(len(check[check <= j]))\n","                cnt += 1\n","            else:\n","                dis.append(len(check[check <= j]) - sum(dis[:cnt]))\n","                cnt += 1\n","                if j == 200:\n","                    dis.append(len(check[check <= 255]) - sum(dis[:cnt+1]))\n","        sub_picture.append(dis)\n","    dist_picture.append(sub_picture)"]},{"cell_type":"markdown","metadata":{"id":"V6PZBDosRy9A"},"source":["IsolationForest: anomaly detection에 활용\n","hyperparameter: n_estimators = 100, contamination = 0.115, random_state = 42\n","사진 데이터 1906개에 대해서 학습 진행 -> 후에 이미지 데이터로 predict"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":486,"status":"ok","timestamp":1665820995059,"user":{"displayName":"Machine Running Learning","userId":"02190580932973673985"},"user_tz":-540},"id":"f7lvEPKjLgbZ","outputId":"af6e7f42-a3c1-45de-b4cb-46690dd08ae4"},"outputs":[{"data":{"text/plain":["IsolationForest(contamination=0.115, random_state=42)"]},"execution_count":329,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.ensemble import IsolationForest\n","iso = IsolationForest(n_estimators = 100, contamination = 0.115, random_state = 42)\n","iso.fit(d_real)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g7WLQAVxUSvK"},"outputs":[],"source":["# 3차의 저장소 경로 지정\n","image_path_picture = '/content/drive/MyDrive/Data/3rd_filtering/picture'\n","image_path_real = '/content/drive/MyDrive/Data/3rd_filtering/real'\n","\n","# label_path = os.listdir(image_path) # listdir에 파일의 경로가 들어있다\n","\n","# label_paths = [os.path.join(image_path,label_path[i]) for i in range(len(label_path))] # L2_#까지 포함된 경로\n","\n","# image_jpg = [os.listdir(label_paths[i]) for i in range(len(label_paths))] # JPG명"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qIujaear2Fe"},"outputs":[],"source":["for i in range(len(dist_picture)):\n","    d_or = pd.DataFrame(dist_picture[i])\n","    print(i)\n","    std_set = []\n","    for j in range(len(d_or)):\n","        std_set.append(np.std(d_or.iloc[j]))\n","    d_or[\"std\"] = std_set\n","    ans = iso.predict(d_or)\n","    print(len(ans[ans==1]))\n","    idx = []\n","    for k in range(len(ans)):\n","        # 이미지 데이터는 -1로서 판단\n","        if ans[k] == -1:\n","            pic_route = os.path.join(image_path_picture, label_path[i])\n","            path = os.path.join(pic_route, image_jpg[i][k])\n","            img = Image.open(image_paths[i][k])\n","            img = np.array(img)\n","            cv_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","            cv2.imwrite(path, cv_image)\n","        else:\n","            real_route = os.path.join(image_path_real, label_path[i])\n","            path = os.path.join(real_route, image_jpg[i][k])\n","            img = Image.open(image_paths[i][k])\n","            img = np.array(img)\n","            cv_image = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n","            cv2.imwrite(path, cv_image)\n"]},{"cell_type":"markdown","metadata":{"id":"Jn2ycdrRevRP"},"source":["이미지 업로드"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxUoPxIrtasV"},"outputs":[],"source":["image_path_final = '/content/drive/MyDrive/Data/3rd_filtering/real'\n","\n","label_path_final = os.listdir(image_path_final) # listdir에 파일의 경로가 들어있다\n","\n","label_paths_final = [os.path.join(image_path_final,label_path_final[i]) for i in range(len(label_path_final))]\n","\n","image_jpg_final = [os.listdir(label_paths_final[i]) for i in range(len(label_paths_final))]\n","\n","image_paths_final = []\n","for i in range(len(label_paths_final)):\n","    sub_paths = []\n","    for j in range(len(image_jpg_final[i])):\n","        sub_paths.append(os.path.join(label_paths_final[i], image_jpg_final[i][j]))\n","    image_paths_final.append(sub_paths)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNDQXIHO1khGTkxX7xRrup0","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"133ROtbMeG4q2Qd2dX-8kFpTYKG4aN5A3","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
