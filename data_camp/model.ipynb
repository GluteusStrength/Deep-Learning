{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4VD4-C-Sgqc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import optim\n",
        "import os\n",
        "import gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt\n",
        "import PIL.Image as pilimg\n",
        "from torch.autograd import Variable\n",
        "from sklearn.metrics import plot_confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpnN4W7wwXh-"
      },
      "source": [
        "Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AjD_0nUwXOx"
      },
      "outputs": [],
      "source": [
        "def valid(data_loader, model):\n",
        "    \"\"\" model inference \"\"\"\n",
        "    n_predict = 0\n",
        "    n_correct = 0\n",
        "    with torch.no_grad():\n",
        "        for X, Y in tqdm.tqdm(data_loader):\n",
        "            X, Y = X.cuda(), Y.cuda()\n",
        "            y_hat = model(X)\n",
        "            y_hat.argmax()\n",
        "\n",
        "            _, predicted = torch.max(y_hat, 1)\n",
        "            \n",
        "            n_predict += len(predicted)\n",
        "\n",
        "            predicted = predicted.unsqueeze(dim=1)\n",
        "            correct = (Y == predicted).squeeze(dim=-1)\n",
        "            n_correct += int(correct.sum())\n",
        "\n",
        "    accuracy = n_correct/n_predict\n",
        "    print(f\"Accuracy: {accuracy} ()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiyv-twpKlM7"
      },
      "outputs": [],
      "source": [
        "def test(data_loader, model):\n",
        "    \"\"\" model inference \"\"\"\n",
        "    n_predict = 0\n",
        "    n_correct = 0\n",
        "    y_pred = []\n",
        "    y_label = []\n",
        "    model.load('/content/drive/MyDrive/Data/model/batch32_lr1e-4_epoch95.pt')\n",
        "    with torch.no_grad():\n",
        "        for X, Y in tqdm.tqdm(data_loader):\n",
        "            X, Y = X.cuda(), Y.cuda()\n",
        "            y_hat = model(X)\n",
        "            y_hat.argmax()\n",
        "            \n",
        "            _, predicted = torch.max(y_hat, 1)\n",
        "            \n",
        "            n_predict += len(predicted)\n",
        "            predicted = predicted.unsqueeze(dim=1)\n",
        "            correct += (Y == predicted).squeeze(dim=-1)\n",
        "            n_correct += int(correct.sum())\n",
        "            \n",
        "    accuracy = n_correct/n_predict\n",
        "    print(f\"Accuracy: {accuracy} ()\")\n",
        "\n",
        "    print(classification_report(y_label, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6rT1owJTCQm"
      },
      "source": [
        "Model\n",
        ": based on vggne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhv4cfV5qCX3"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.conv_layer1 = torch.nn.Sequential(   #224*224*3\n",
        "            torch.nn.Conv2d(1, 64, kernel_size=3, padding=1),   #224x224x64\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.conv_layer2 = torch.nn.Sequential(   \n",
        "            torch.nn.Conv2d(64, 128, kernel_size=3 , padding=1),   #112x112x128\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )  \n",
        "\n",
        "        self.conv_layer3 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(128, 256, kernel_size=3 , padding=1),   #56x56x256\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.conv_layer4 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(256, 512, kernel_size=3 , padding=1),   #28x28x512\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.conv_layer5 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=3 , padding=1),   #14x14x512\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2),   #-> 7x7x512로 변화\n",
        "        )\n",
        "\n",
        "        self.fc6 = torch.nn.Linear(7*7*512, 4096, bias = True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc6.weight)\n",
        "        self.layer6 = torch.nn.Sequential(\n",
        "            self.fc6,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(4096),\n",
        "            torch.nn.Dropout(p=0.15)\n",
        "        )\n",
        "\n",
        "        self.fc7 = torch.nn.Linear(4096, 4096, bias = True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc7.weight)\n",
        "        self.layer7 = torch.nn.Sequential(\n",
        "            self.fc7,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(4096),\n",
        "            torch.nn.Dropout(p=0.15)\n",
        "        )\n",
        "\n",
        "        self.fc8 = torch.nn.Linear(4096, 1000, bias = True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc8.weight)\n",
        "        self.layer8 = torch.nn.Sequential(\n",
        "            self.fc8,\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.BatchNorm1d(1000),\n",
        "            torch.nn.Dropout(p=0.15)\n",
        "        )\n",
        "\n",
        "        self.fc9 = torch.nn.Linear(1000, 20, bias = True)\n",
        "        torch.nn.init.xavier_uniform_(self.fc9.weight)\n",
        "    \n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                torch.nn.init.uniform_(m.weight.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv_layer1(x)\n",
        "        out = self.conv_layer2(out)\n",
        "        out = self.conv_layer3(out)\n",
        "        out = self.conv_layer4(out)\n",
        "        out = self.conv_layer5(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.fc9(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "model = Net()\n",
        "model = model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWyLyaMzzePJ"
      },
      "outputs": [],
      "source": [
        "saved_model_path = ('/content/drive/MyDrive/Data/model/batch32_lr1e-4_epoch95.pt')\n",
        "\n",
        "model = torch.load(saved_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHlt5Ds9-F_v"
      },
      "outputs": [],
      "source": [
        "# print(model.state_dict())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0PcnHKHut7d"
      },
      "source": [
        "Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSD-ubH2utoa"
      },
      "outputs": [],
      "source": [
        "model_path = ('/content/drive/MyDrive/Data/model/batch16_lr1e-4_epoch')\n",
        "\n",
        "plt_path = ('/content/drive/MyDrive/Data/learning_curve/batch16_lr1e-4_3rdtime.png')\n",
        "\n",
        "data_batch_size = 32\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
        "\n",
        "training_epochs = 10000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MP945SqTGu7"
      },
      "source": [
        "Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xdIwIZ_zAb8"
      },
      "outputs": [],
      "source": [
        "# train_x = np.load('/content/drive/MyDrive/Data/Dataset/train_x.npy')\n",
        "# train_y = np.load('/content/drive/MyDrive/Data/Dataset/train_y.npy')\n",
        "\n",
        "# valid_x = np.load('/content/drive/MyDrive/Data/Dataset/validation_x.npy')\n",
        "# valid_y = np.load('/content/drive/MyDrive/Data/Dataset/validation_y.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MvU2Z3hzA8b",
        "outputId": "032413ea-c251-4ec5-870e-3d9922d7d190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(21916, 1, 224, 224) (21916, 1) (1994, 1, 224, 224) (1994, 1)\n"
          ]
        }
      ],
      "source": [
        "# print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4XrwLyoy2Uv"
      },
      "outputs": [],
      "source": [
        "train_x = np.load('/content/drive/MyDrive/Data/Dataset/train_x.npy')\n",
        "train_y = np.load('/content/drive/MyDrive/Data/Dataset/train_y.npy')\n",
        "\n",
        "valid_x = np.load('/content/drive/MyDrive/Data/Dataset/validation_x.npy')\n",
        "valid_y = np.load('/content/drive/MyDrive/Data/Dataset/validation_y.npy')\n",
        "\n",
        "train_x = torch.from_numpy(train_x).float()\n",
        "train_y = torch.from_numpy(train_y).long()\n",
        "\n",
        "valid_x = torch.from_numpy(valid_x).float()\n",
        "valid_y = torch.from_numpy(valid_y).long()\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(train_x, train_y)\n",
        "valid_data = torch.utils.data.TensorDataset(valid_x, valid_y)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=data_batch_size, shuffle=True)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=data_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = np.load('/content/drive/MyDrive/Data/Dataset/test_x.npy')\n",
        "test_y = np.load('/content/drive/MyDrive/Data/Dataset/test_y.npy')"
      ],
      "metadata": {
        "id": "oetCEv8BMW1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot = plot_confusion_matrix(model, \n",
        "                            test_x, test_y,\n",
        "                            cmap=plt.cm.Blue)\n",
        "plt.save('content/drive/MyDrive/Data/confusion_matrix/batch32_lr1e-4_epoch95.png')"
      ],
      "metadata": {
        "id": "Yx4J9ocZMBR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSb1Zb4yvWLb"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNvZenzwupdr"
      },
      "outputs": [],
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "losses = []\n",
        "before_model_path = 'Null'\n",
        "\n",
        "for epoch in range(training_epochs):\n",
        "    model.train()\n",
        "    cost = 0\n",
        "    n_batches = 0\n",
        "    for X, y in tqdm.tqdm(train_loader):\n",
        "        X, y = X.cuda(), y.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        y_hat = model(X)\n",
        "        y = y.squeeze(dim=-1)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        cost += loss.item()\n",
        "        n_batches += 1\n",
        "\n",
        "    cost /= n_batches\n",
        "    losses.append(cost)\n",
        "    print('[Epoch: {:>4} cost = {:>.9}'.format(epoch+1, cost))\n",
        "    print(\"Dev\")\n",
        "    valid(valid_loader, model)\n",
        "    if min(losses) == cost:\n",
        "        if os.path.exists(before_model_path):\n",
        "            os.remove(before_model_path)\n",
        "        after_model_path = model_path + str(epoch+1) + '_3rdtime.pt'\n",
        "        before_model_path = after_model_path\n",
        "        print('save model')\n",
        "        torch.save(model, after_model_path)\n",
        "\n",
        "    plt.plot(losses)\n",
        "    plt.savefig(plt_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqXH6FisCiSf"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# data = np.load('/content/drive/MyDrive/Data/Dataset/test_x.npy')\n",
        "# data_y = np.load('/content/drive/MyDrive/Data/Dataset/test_y.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhMSBLopTkBg",
        "outputId": "4abd522d-ed56-4b85-9caa-e367540b5c23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2026"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(data_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ts-NtZA2T_fA",
        "outputId": "685af5a8-ea03-4e01-c997-8a64f058e61d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2026"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twCRmMoVUfSr"
      },
      "outputs": [],
      "source": [
        "# def test(data_loader, model):\n",
        "#     \"\"\" model inference \"\"\"\n",
        "#     n_predict = 0\n",
        "#     n_correct = 0\n",
        "#     model.load_state_dict(torch.load(\"content/drive/MyDrive/Data/Dataset/model3.pt\"))\n",
        "#     with torch.no_grad():\n",
        "#         for X, Y in tqdm.tqdm(data_loader):\n",
        "#             X, Y = X.cuda(), Y.cuda()\n",
        "#             y_hat = model(X)\n",
        "#             y_hat.argmax()\n",
        "            \n",
        "#             _, predicted = torch.max(y_hat, 1)\n",
        "            \n",
        "#             n_predict += len(predicted)\n",
        "#             n_correct += (Y == predicted).sum()\n",
        "            \n",
        "#     accuracy = n_correct/n_predict\n",
        "#     print(f\"Accuracy: {accuracy} ()\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze(model):\n",
        "    for p in model.parameters():\n",
        "        p.requires_grad = False\n",
        "\n",
        "    return model.eval()"
      ],
      "metadata": {
        "id": "ALdEot-LmWAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, loader):\n",
        "    total_preds = []\n",
        "    total_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        model.cuda()\n",
        "        for img, label in tqdm.tqdm(loader):\n",
        "            img = img.cuda()\n",
        "            label = label.cuda()\n",
        "            \n",
        "            pred = model(img)\n",
        "            total_preds.append(pred)\n",
        "            total_labels.append(label)\n",
        "            \n",
        "        total_preds = torch.cat(total_preds).argmax(dim=1).cpu().numpy()\n",
        "        total_labels = torch.cat(total_labels).cpu().numpy()\n",
        "\n",
        "        result = classification_report(total_labels, total_preds, output_dict=True)\n",
        "        \n",
        "    return pd.DataFrame(result)"
      ],
      "metadata": {
        "id": "SzvN6AnyfQ1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_across_seeds(accs, f1s, result_df, num_classes=20):\n",
        "    accs = torch.tensor(accs)\n",
        "    f1s = torch.tensor(f1s)\n",
        "    \n",
        "    assert torch.all(torch.abs(accs[1:] - accs[:1]) < 1e-1) and torch.all(torch.abs(f1s[1:] - f1s[:1]) < 1e-1), \"test results are not compatible \\n{}\\n{}\".format(accs, f1s)\n",
        "\n",
        "    print(\"*** CLASSWISE RESULT ***\")\n",
        "    cwise_result = result_df.loc[['f1-score', 'recall'], [str(i) for i in range(num_classes)]]\n",
        "    cwise_result = cwise_result.rename(index={'f1-score' : 'f1', 'recall' : 'acc'})\n",
        "    print(cwise_result)\n",
        "    \n",
        "    print(\"\\n*** AVG RESULT ***\")\n",
        "    avg_result = pd.Series({'f1' : result_df.loc['f1-score', 'macro avg'], 'acc' : result_df['accuracy'].values[0]})\n",
        "    print(avg_result)"
      ],
      "metadata": {
        "id": "3RJjOPzuiybO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x = np.load('/content/drive/MyDrive/Data/Dataset/test_x.npy')\n",
        "test_y = np.load('/content/drive/MyDrive/Data/Dataset/test_y.npy')\n",
        "\n",
        "test_x = torch.from_numpy(test_x).float()\n",
        "test_y = torch.from_numpy(test_y).long()\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(test_x, test_y)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=32, shuffle=True)"
      ],
      "metadata": {
        "id": "0oxbc_1gG3rm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEEDS = [0, 5, 10]\n",
        "\n",
        "\n",
        "ACC_LIST = []\n",
        "F1_LIST = []\n",
        "\n",
        "for seed in SEEDS:\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    model = freeze(model)\n",
        "    RESULT_DF = test(model, test_loader)\n",
        "    ACC_LIST.append(RESULT_DF['accuracy'].values[0])\n",
        "    F1_LIST.append(RESULT_DF.loc['f1-score', 'macro avg'])\n",
        "\n",
        "check_across_seeds(ACC_LIST, F1_LIST, RESULT_DF)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pPJtdAvi0Kj",
        "outputId": "b172b172-38c7-468a-92b7-92d39730da7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 63/63 [00:08<00:00,  7.29it/s]\n",
            "100%|██████████| 63/63 [00:08<00:00,  7.23it/s]\n",
            "100%|██████████| 63/63 [00:08<00:00,  7.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** CLASSWISE RESULT ***\n",
            "            0         1         2         3         4         5         6  \\\n",
            "f1   0.648649  0.842491  0.535714  0.852273  0.797203  0.608696  0.617647   \n",
            "acc  0.750000  0.804196  0.750000  0.815217  0.838235  0.617647  0.608696   \n",
            "\n",
            "            7         8         9        10        11        12        13  \\\n",
            "f1   0.890701  0.769231  0.489796  0.891344  0.785714  0.765101  0.676923   \n",
            "acc  0.810089  0.785714  0.610169  0.858156  0.785714  0.802817  0.785714   \n",
            "\n",
            "           14        15        16        17        18        19  \n",
            "f1   0.567901  0.835979  0.757895  0.802721  0.588235  0.809524  \n",
            "acc  0.741935  0.877778  0.727273  0.797297  0.615385  0.850000  \n",
            "\n",
            "*** AVG RESULT ***\n",
            "f1     0.726687\n",
            "acc    0.786359\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XD7faZhPyAJM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}