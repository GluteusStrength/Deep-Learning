{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c4e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install ipython seaborn matplotlib torchvision tqdm pillow pyyaml requests pandas opencv-python torch protobuf psutil\n",
    "# Git clone 진행\n",
    "# 혹시 git이 설치 안 된 상태라면 git 설치를 우선 해줘야 한다. 자세한 가이드라인은 따로 참조할 것.\n",
    "# 1회만 실행하면 된다\n",
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%pip install -qr requriements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7ba411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 module upload\n",
    "import torch\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "# 이미지를 한 번에 긁어모으기 위한 glob 모듈\n",
    "from glob import glob\n",
    "# Image를 open\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "647490b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow()후 커널 dead 현상 제거\n",
    "# 실행 시 계속 실행\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f57ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda 연산\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ae39f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('GeForce RTX 3060 Laptop GPU', device(type='cuda'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 내 gpu 환경\n",
    "torch.cuda.get_device_name(0), device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2887ac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\user/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-3-30 Python-3.9.13 torch-1.13.1+cu116 CUDA:0 (GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "210cd5365d104295b5129e2bf28e9d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/166M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Fusing layers... \n",
      "YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# yolov5 model load\n",
    "# 따로 구축하진 않고 있는 parameter 활용\n",
    "# parameter 활용 시 customizing 하는 방법 생각\n",
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7757ffb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\recognition_project\\yolov5\n"
     ]
    }
   ],
   "source": [
    "# data set download\n",
    "# 내 현재의 작업 환경으로 다운로드가 된다.\n",
    "#!curl -L \"https://public.roboflow.com/ds/eL4QUdkpSR?key=0ikL5WLM1w\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n",
    "# 작업환경 change\n",
    "%cd \"C:\\\\Users\\\\user\\\\Desktop\\\\recognition_project\\\\yolov5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0dc0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Desktop\\\\recognition_project\\\\yolov5'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bae50c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train image 경로, test image 경로를 통해 전반적으로 list로 모이게 된다\n",
    "train_img = glob(\"./new_data_sets/train/images/*.jpg\")\n",
    "val_img = glob(\"./new_data_sets/valid/images/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f783106",
   "metadata": {},
   "source": [
    "YAML: 데이터를 표현하기 위한 포맷 중 하나\n",
    "- 사람이 쉽게 읽고 쓸 수 있는 텍스트 기반 format, 파이썬의 딕셔너리와 유사한 형태로 데이터 표현\n",
    "- YAML 파일은 Key-value 쌍으로 구성\n",
    "- Key는 콜론으로 value와 구분, indentation을 통해 데이터의 계층 구조를 나타낸다\n",
    "- pytorch와 같은 deep learning library에서는 모델 구성을 정의하는 yaml 파일을 사용하기도 한다\n",
    "- YOLOv5 -> 모델 구성을 정의하기 위해 YAML 파일 활용. 이 파일에는 모델의 LAYER, HYPERPARMETER 등을 포함하며, 모델을 학습하기 전에 수정 가능하다. 이를 통해 모델 구성 실험, 최적의 성능을 찾을 수 있다.\n",
    "- 그리고 YOLOv5 모델 학습을 위해서는 학습 데이터 및 라벨 데이터 모두를 YAML 파일로 표현해야 한다.\n",
    "- yaml 파일에는 학습 데이터의 경로, 이미지와 라벨 파일의 이름, 이미지 및 라벨 파일의 경로 및 형식, 데이터셋 분할 방법 등의 정보가 포함되어 있다.\n",
    "- label 파일을 표현하는 yaml 파일은 일반적으로 coco 형식을 따르며, 각 라벨의 이름, 인덱스, RGB 색상 등의 정보가 포함 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0274a90b",
   "metadata": {},
   "source": [
    "!python detect.py --source \"경로\": 이 코드의 의미\n",
    "- --source option: object detection을 수행할 이미지나 비디오 파일 또는 directory 경로를 저장한다.\n",
    "- \"경로\" 디렉토리 내의 이미지 파일을 대상으로 object detection을 수행한다.\n",
    "- YOLOv5 모델을 사용하여 \"경로\" 디렉토리 내의 이미지 파일에서 object detection을 수행하고, 결과를 출력하는 스크립트를 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1dda4f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\Users\\user\\Desktop\\recognition_project\\detect.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# rough YOLOv5 detect\n",
    "!python detect.py --source \"./data/images/\" --cfg \"./yolov5x.yaml\" --weights ./models/yolov5x.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b92e3f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['runs/detect/exp2\\\\bus.jpg', 'runs/detect/exp2\\\\tkwls.png', 'runs/detect/exp2\\\\zidane.jpg']\n"
     ]
    }
   ],
   "source": [
    "img_paths = glob(\"runs/detect/exp2/*\")\n",
    "print(img_paths)\n",
    "img = cv2.imread(img_paths[1])\n",
    "plt.figure(figsize = (300, 300))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4bd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.yaml file open -> 해당 data set의 정보를 파악한다.\n",
    "with open(\"./new_data_sets/data.yaml\", \"r\") as f:\n",
    "    data = yaml.load(f, Loader = yaml.FullLoader)\n",
    "data[\"train\"] = \"./\"\n",
    "data[\"test\"] = \"\"\n",
    "data[\"val\"] = \"\"\n",
    "with open(\"\", \"w\") as f:\n",
    "    yaml.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506522a",
   "metadata": {},
   "source": [
    "### 확인 결과\n",
    "- train: train/images\n",
    "- validation: valid/images\n",
    "- nc: number of class -> 2개\n",
    "- names: [\"mask\", \"no-mask\"]\n",
    "- 이들은 annotation set이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7678262f",
   "metadata": {},
   "source": [
    "모델 학습 부분\n",
    "- -epochs: epoch 수\n",
    "- -data + data.yaml 파일 경로 (데이터셋 정보가 적힌 yaml 파일이다)\n",
    "- -weights: Pre-trained 모델 파일 경로(pt 형식 파일)\n",
    "- -batch: batch_size\n",
    "- -cfg: yolov5 architecture yaml 파일 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --data \"./yolov5/new_data_sets/data.yaml\" --epochs 30 --batch 16 --cfg \"./models/yolov5s.yaml\" --weights ./models/yolov5s.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581069b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f56644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
